# Platform Architecture Update - 2025-11-07

## ðŸŽ¯ Major Changes: Chat & Trace Architecture Refactoring

### Summary
Complete architectural refactoring separating chat communication (REST + SSE) from trace debugging (WebSocket). This implements the correct architecture where:
- **Chat**: UI â†’ REST API â†’ Chat Service â†’ A2A SSE â†’ Agent
- **Trace**: Agent â†’ LLM Proxy â†’ WebSocket â†’ UI Trace View

### 1. New Service: LLM Proxy Service
**Created**: `/repos/llm-proxy-service/` (Port 8006)

**Purpose**: Centralized LLM proxy with trace event collection via WebSocket

**Components**:
- `app/websocket/manager.py` - WebSocket connection manager for trace events
- `app/websocket/__init__.py` - WebSocket endpoints (`/ws/trace/{agent_id}`)
- `app/api/__init__.py` - LLM proxy API (placeholder for future LLM interception)
- `app/core/database.py` - Database models (LLMCall, TraceEvent, ToolCall)
- `app/main.py` - FastAPI application with database initialization

**Database**: `llm_proxy_db`
- Tables: `llm_calls`, `trace_events`, `tool_calls`
- Stores all LLM interactions and trace events for debugging

**Docker Configuration**:
- Added to `docker-compose.dev.yml` on port 8006
- Added to `start-dev.sh` service list
- Added to `init-db.sql` database initialization

**Health Check**: http://localhost:8006/health

### 2. Chat Service Complete Refactoring
**Modified**: `/repos/chat-service/` (Port 8003)

**Major Changes**:
1. **Removed WebSocket completely**
   - Deleted `app/websocket/` directory
   - Removed WebSocket endpoint from `app/main.py`
   - Removed WebSocket dependencies

2. **Implemented REST + SSE Streaming**
   - New endpoint: `POST /api/chat/sessions/{session_id}/messages/stream`
   - Streams agent responses via Server-Sent Events (SSE)
   - Direct A2A protocol integration with agents

3. **Enhanced Session Management**
   - `GET /api/chat/sessions/` - List all user sessions (with agent_id filter)
   - `GET /api/chat/sessions/{session_id}` - Get session details
   - `DELETE /api/chat/sessions/{session_id}` - Delete session
   - Multi-user isolation via `user_id` field

4. **Chat History APIs**
   - `GET /api/chat/sessions/{session_id}/messages/` - Get message list
   - `GET /api/chat/sessions/{session_id}/history` - Get complete chat history (session + messages)
   - All messages stored in database for persistence

**Updated Files**:
- `app/main.py` - Removed WebSocket imports, updated description
- `app/api/v1/messages.py` - Complete rewrite with SSE streaming
- `app/api/v1/sessions.py` - Added list endpoint, session management
- `app/core/database.py` - (No changes, already had chat history tables)

**Health Check**: http://localhost:8003/health

### 3. Infrastructure Updates

**Database Changes**:
- Added `llm_proxy_db` to PostgreSQL initialization
- Updated `repos/infra/init-db.sql`

**Service Configuration**:
- Updated `start-dev.sh` to include llm-proxy-service
- Updated `docker-compose.dev.yml`:
  - Added llm-proxy-service definition
  - Added `LLM_PROXY_SERVICE_URL` to api-gateway environment

### 4. Architecture Flow

#### Chat Flow (REST + SSE):
```
UI â†’ POST /api/chat/sessions/{id}/messages/stream
  â†“ (SSE Response)
Chat Service
  â†“ (A2A SSE Stream)
Agent (Math/Text)
  â†“ (Gemini LLM)
Response streamed back via SSE
```

#### Trace Flow (WebSocket):
```
Agent â†’ LLM Calls
  â†“
LLM Proxy (intercepts)
  â†“
WebSocket: ws://localhost:8006/ws/trace/{agent_id}
  â†“
UI Trace View (real-time logs)
```

### 5. Multi-User Isolation

**Chat Isolation**:
- Sessions are user-specific (`user_id` field)
- Each user only sees their own sessions
- Session list filtered by current user
- Access control on all session operations

**Trace Isolation** (To Be Implemented):
- Trace WebSocket connections will use `user_id + agent_id` routing
- LLM Proxy will separate trace events per user-agent combination

### 6. Benefits of New Architecture

1. **Proper Separation of Concerns**
   - Chat uses HTTP/SSE (standard, cacheable, RESTful)
   - Trace uses WebSocket (real-time, bidirectional)

2. **Better Scalability**
   - SSE is easier to scale than WebSocket for chat
   - Dedicated trace service can be scaled independently

3. **Improved Debugging**
   - All LLM interactions logged in centralized database
   - Trace events persist for post-mortem analysis
   - Clear separation between chat data and debug data

4. **Standards Compliance**
   - A2A protocol natively supports SSE streaming
   - No need for WebSocket â†’ SSE conversion

### 7. Next Steps (Pending Implementation)

#### Backend:
- [ ] Implement LLM proxy functionality (intercept agent LLM calls)
- [ ] Add trace history retrieval API
- [ ] Configure agents to use platform LLM proxy

#### Frontend:
- [ ] Update ChatPlayground to use REST + SSE
- [ ] Update TraceView to connect to llm-proxy WebSocket
- [ ] Implement chat history sidebar
- [ ] Session management UI (list, load, delete sessions)

#### Testing:
- [ ] Playwright E2E tests for chat flow
- [ ] Playwright E2E tests for trace WebSocket
- [ ] Multi-user isolation verification

### 8. Breaking Changes

âš ï¸ **Chat Service API Changes**:
- WebSocket endpoint `/ws/chat/{session_id}` **REMOVED**
- Use REST endpoint `/api/chat/sessions/{session_id}/messages/stream` instead
- Response format changed to SSE instead of WebSocket messages

### 9. Migration Guide

**For Frontend Developers**:
1. Replace WebSocket connection with EventSource:
```typescript
// Old (WebSocket)
const ws = new WebSocket(`ws://localhost:9050/ws/chat/${sessionId}?token=${token}`);

// New (SSE)
const eventSource = new EventSource(`http://localhost:9050/api/chat/sessions/${sessionId}/messages/stream`);
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.type === 'text_token') {
    // Handle streaming token
  }
};
```

2. Connect to trace WebSocket separately:
```typescript
const traceWs = new WebSocket(`ws://localhost:8006/ws/trace/${agentId}?token=${token}`);
```

### 10. Files Changed

**New Files**:
- `/repos/llm-proxy-service/` (entire service)
- `/repos/llm-proxy-service/app/main.py`
- `/repos/llm-proxy-service/app/websocket/manager.py`
- `/repos/llm-proxy-service/app/websocket/__init__.py`
- `/repos/llm-proxy-service/app/api/__init__.py`
- `/repos/llm-proxy-service/app/core/database.py`
- `/repos/llm-proxy-service/Dockerfile.dev`
- `/repos/llm-proxy-service/.python-version`
- `/repos/llm-proxy-service/pyproject.toml`
- `/repos/llm-proxy-service/uv.lock`

**Modified Files**:
- `/repos/chat-service/app/main.py` - Removed WebSocket
- `/repos/chat-service/app/api/v1/messages.py` - Complete rewrite
- `/repos/chat-service/app/api/v1/sessions.py` - Added session list
- `/repos/infra/docker-compose.dev.yml` - Added llm-proxy-service
- `/repos/infra/init-db.sql` - Added llm_proxy_db
- `/start-dev.sh` - Added llm-proxy-service to service list

**Deleted Files**:
- `/repos/chat-service/app/websocket/chat_handler.py`
- `/repos/chat-service/app/websocket/manager.py`
- `/repos/chat-service/app/websocket/__init__.py`

---

**Version**: 2.1
**Date**: 2025-11-07
**Author**: Claude Code Assistant
**Verified**: Backend services running and tested
